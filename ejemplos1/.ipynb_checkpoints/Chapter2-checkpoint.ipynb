{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción al Procesamiento de Imágenes\n",
    "## Sampling & Fourier Transform "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c anaconda scikit-image\n",
    "#conda install -c anaconda scipy\n",
    "#conda install -c anaconda pillow\n",
    "#pip install --upgrade --force-reinstall scipy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0e28e57b5654>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "from PIL import Image\n",
    "from skimage.io import imread, imshow, show\n",
    "import scipy.fftpack as fp\n",
    "from scipy import ndimage, misc, signal\n",
    "#from scipy.stats import signaltonoise\n",
    "from skimage import data, img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import numpy.fft\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../images/clock.jpg\") # the original small clock image\n",
    "pylab.imshow(im), pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = im.resize((im.width*5, im.height*5), Image.NEAREST) # nearest neighbor interpolation\n",
    "pylab.figure(figsize=(10,10)), pylab.imshow(im1), pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = im.resize((im.width*5, im.height*5), Image.BILINEAR) # up-sample with bi-linear interpolation\n",
    "pylab.figure(figsize=(10,10)), pylab.imshow(im1), pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.resize((im.width*10, im.height*10), Image.BICUBIC).show() # bi-cubic interpolation\n",
    "pylab.figure(figsize=(10,10)), pylab.imshow(im1), pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../images/tajmahal.jpg\")\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im.resize((im.width//5, im.height//5))\n",
    "pylab.figure(figsize=(15,10)), pylab.imshow(im), pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../images/tajmahal.jpg\")\n",
    "im = im.resize((im.width//5, im.height//5), Image.ANTIALIAS)\n",
    "pylab.figure(figsize=(15,10)), pylab.imshow(im), pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imread('../images/umbc.png')\n",
    "im1 = im.copy()\n",
    "pylab.figure(figsize=(20,15))\n",
    "for i in range(4):\n",
    "    pylab.subplot(2,2,i+1), pylab.imshow(im1, cmap='gray'), pylab.axis('off')\n",
    "    pylab.title('image size = ' + str(im1.shape[1]) + 'x' + str(im1.shape[0]))\n",
    "    im1 = rescale(im1, scale = 0.5, multichannel=True, anti_aliasing=False)\n",
    "pylab.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = rescale(im1, scale = 0.5, multichannel=True, anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantizing with PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../images/parrot.jpg')\n",
    "pylab.figure(figsize=(20,30))\n",
    "num_colors_list = [1 << n for n in range(8,0,-1)]\n",
    "snr_list = []\n",
    "i = 1\n",
    "for num_colors in num_colors_list:\n",
    "    im1 = im.convert('P', palette=Image.ADAPTIVE, colors=num_colors)\n",
    "    pylab.subplot(4,2,i), pylab.imshow(im1), pylab.axis('off')\n",
    "    snr_list.append(signaltonoise(im1, axis=None))\n",
    "    pylab.title('Image with # colors = ' + str(num_colors) + ' SNR = ' +\n",
    "    str(np.round(snr_list[i-1],3)), size=20)\n",
    "    i += 1\n",
    "pylab.subplots_adjust(wspace=0.2, hspace=0)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(num_colors_list, snr_list, 'r.-')\n",
    "pylab.xlabel('# colors in the image')\n",
    "pylab.ylabel('SNR')\n",
    "pylab.title('Change in SNR w.r.t. # colors')\n",
    "pylab.xscale('log', basex=2)\n",
    "pylab.gca().invert_xaxis()\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT with the scipy.fftpack module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.array(Image.open('../images/rhino.jpg').convert('L')) # we shall work with grayscale image\n",
    "snr = signaltonoise(im, axis=None)\n",
    "print('SNR for the original image = ' + str(snr))\n",
    "# SNR for the original image = 2.023722773801701\n",
    "# now call FFT and IFFT\n",
    "freq = fp.fft2(im)\n",
    "im1 = fp.ifft2(freq).real\n",
    "snr = signaltonoise(im1, axis=None)\n",
    "print('SNR for the image obtained after reconstruction = ' + str(snr))\n",
    "# SNR for the image obtained after reconstruction = 2.0237227738013224\n",
    "assert(np.allclose(im, im1)) # make sure the forward and inverse FFT are close to each other\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.subplot(121), pylab.imshow(im, cmap='gray'), pylab.axis('off')\n",
    "pylab.title('Original Image', size=20)\n",
    "pylab.subplot(122), pylab.imshow(im1, cmap='gray'), pylab.axis('off')\n",
    "pylab.title('Image obtained after reconstruction', size=20)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the quadrants are needed to be shifted around in order that the low spatial frequencies are in the center of the 2D fourier-transformed image.\n",
    "freq2 = fp.fftshift(freq)\n",
    "pylab.figure(figsize=(10,10)), pylab.imshow( (20*np.log10( 0.1 + freq2)).astype(int)), pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT with the numpy.fft module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.fft as fp\n",
    "im1 = rgb2gray(imread('../images/house.png'))\n",
    "pylab.figure(figsize=(12,10))\n",
    "freq1 = fp.fft2(im1)\n",
    "im1_ = fp.ifft2(freq1).real\n",
    "pylab.subplot(2,2,1), pylab.imshow(im1, cmap='gray'), pylab.title('Original Image', size=20)\n",
    "pylab.subplot(2,2,2), pylab.imshow(20*np.log10( 0.01 +\n",
    "np.abs(fp.fftshift(freq1))), cmap='gray')\n",
    "pylab.title('FFT Spectrum Maginitude', size=20)\n",
    "pylab.subplot(2,2,3), pylab.imshow(np.angle(fp.fftshift(freq1)),cmap='gray')\n",
    "pylab.title('FFT Phase', size=20)\n",
    "pylab.subplot(2,2,4), pylab.imshow(np.clip(im1_,0,255), cmap='gray')\n",
    "pylab.title('Reconstructed Image', size=20)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = rgb2gray(imread('../images/house2.png'))\n",
    "pylab.figure(figsize=(12,10))\n",
    "freq2 = fp.fft2(im2)\n",
    "im2_ = fp.ifft2(freq2).real\n",
    "pylab.subplot(2,2,1), pylab.imshow(im2, cmap='gray'), pylab.title('Original Image', size=20)\n",
    "pylab.subplot(2,2,2), pylab.imshow(20*np.log10( 0.01 +\n",
    "np.abs(fp.fftshift(freq2))), cmap='gray')\n",
    "pylab.title('FFT Spectrum Maginitude', size=20)\n",
    "pylab.subplot(2,2,3), pylab.imshow(np.angle(fp.fftshift(freq2)), cmap='gray')\n",
    "pylab.title('FFT Phase', size=20)\n",
    "pylab.subplot(2,2,4), pylab.imshow(np.clip(im2_,0,255), cmap='gray')\n",
    "pylab.title('Reconstructed Image', size=20)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(figsize=(20,15))\n",
    "im1_ = fp.ifft2(np.vectorize(complex)(freq1.real, freq2.imag)).real\n",
    "im2_ = fp.ifft2(np.vectorize(complex)(freq2.real, freq1.imag)).real\n",
    "pylab.subplot(211), pylab.imshow(np.clip(im1_,0,255), cmap='gray')\n",
    "pylab.title('Reconstructed Image (Re(F1) + Im(F2))', size=20)\n",
    "pylab.subplot(212), pylab.imshow(np.clip(im2_,0,255), cmap='gray')\n",
    "pylab.title('Reconstructed Image (Re(F2) + Im(F1))', size=20)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying convolution to a grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = rgb2gray(imread('../images/cameraman.jpg')).astype(float)\n",
    "print(np.max(im))\n",
    "print(im.shape)\n",
    "blur_box_kernel = np.ones((3,3)) / 9\n",
    "edge_laplace_kernel = np.array([[0,1,0],[1,-4,1],[0,1,0]])\n",
    "im_blurred = signal.convolve2d(im, blur_box_kernel)\n",
    "im_edges = np.clip(signal.convolve2d(im, edge_laplace_kernel), 0, 1)\n",
    "fig, axes = pylab.subplots(ncols=3, sharex=True, sharey=True, figsize=(18,6))\n",
    "axes[0].imshow(im, cmap=pylab.cm.gray)\n",
    "axes[0].set_title('Original Image', size=20)\n",
    "axes[1].imshow(im_blurred, cmap=pylab.cm.gray)\n",
    "axes[1].set_title('Box Blur', size=20)\n",
    "axes[2].imshow(im_edges, cmap=pylab.cm.gray)\n",
    "axes[2].set_title('Laplace Edge Detection', size=20)\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying convolution to a color (RGB) image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = misc.imread('../images/tajmahal.jpg')/255 # scale each pixel value in [0,1]\n",
    "print(np.max(im))\n",
    "print(im.shape)\n",
    "emboss_kernel = np.array([[-2,-1,0],[-1,1,1],[0,1,2]])\n",
    "edge_schar_kernel = np.array([[ -3-3j, 0-10j, +3 -3j], [-10+0j, 0+ 0j, +10+0j], [ -3+3j, 0+10j, +3 +3j]])\n",
    "im_embossed = np.ones(im.shape)\n",
    "im_edges = np.ones(im.shape)\n",
    "for i in range(3):\n",
    "    im_embossed[...,i] = np.clip(signal.convolve2d(im[...,i], emboss_kernel, mode='same', boundary=\"symm\"),0,1)\n",
    "for i in range(3):\n",
    "    im_edges[:,:,i] = np.clip(np.real(signal.convolve2d(im[...,i], edge_schar_kernel, mode='same', boundary=\"symm\")),0,1)\n",
    "fig, axes = pylab.subplots(nrows=3, figsize=(20, 30))\n",
    "axes[0].imshow(im)\n",
    "axes[0].set_title('Original Image', size=20)\n",
    "axes[1].imshow(im_embossed)\n",
    "axes[1].set_title('Embossed Image', size=20)\n",
    "axes[2].imshow(im_edges)\n",
    "axes[2].set_title('Schar Edge Detection', size=20)\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution with SciPy ndimage.convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = misc.imread('../images/victoria_memorial.png').astype(np.float) # read as float\n",
    "print(np.max(im))\n",
    "sharpen_kernel = np.array([0, -1, 0, -1, 5, -1, 0, -1, 0]).reshape((3, 3, 1))\n",
    "emboss_kernel = np.array(np.array([[-2,-1,0],[-1,1,1],[0,1,2]])).reshape((3, 3, 1))\n",
    "im_sharp = ndimage.convolve(im, sharpen_kernel, mode='nearest')\n",
    "im_sharp = np.clip(im_sharp, 0, 255).astype(np.uint8) # clip (0 to 255) and convert to unsigned int\n",
    "im_emboss = ndimage.convolve(im, emboss_kernel, mode='nearest')\n",
    "im_emboss = np.clip(im_emboss, 0, 255).astype(np.uint8)\n",
    "\n",
    "pylab.figure(figsize=(10,15))\n",
    "pylab.subplot(311), pylab.imshow(im.astype(np.uint8)), pylab.axis('off')\n",
    "pylab.title('Original Image', size=25)\n",
    "pylab.subplot(312), pylab.imshow(im_sharp), pylab.axis('off')\n",
    "pylab.title('Sharpened Image', size=25)\n",
    "pylab.subplot(313), pylab.imshow(im_emboss), pylab.axis('off')\n",
    "pylab.title('Embossed Image', size=25)\n",
    "pylab.tight_layout()\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template matching with cross-correlation between the image and template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_image = misc.face(gray=True) - misc.face(gray=True).mean()\n",
    "template_image = np.copy(face_image[300:365, 670:750]) # right eye\n",
    "template_image -= template_image.mean()\n",
    "face_image = face_image + np.random.randn(*face_image.shape) * 50 # add random noise\n",
    "correlation = signal.correlate2d(face_image, template_image, boundary='symm', mode='same')\n",
    "y, x = np.unravel_index(np.argmax(correlation), correlation.shape) # find the match\n",
    "fig, (ax_original, ax_template, ax_correlation) = pylab.subplots(3, 1, figsize=(6, 15))\n",
    "ax_original.imshow(face_image, cmap='gray')\n",
    "ax_original.set_title('Original', size=20)\n",
    "ax_original.set_axis_off()\n",
    "ax_template.imshow(template_image, cmap='gray')\n",
    "ax_template.set_title('Template', size=20)\n",
    "ax_template.set_axis_off()\n",
    "ax_correlation.imshow(correlation, cmap='afmhot')\n",
    "ax_correlation.set_title('Cross-correlation', size=20)\n",
    "ax_correlation.set_axis_off()\n",
    "ax_original.plot(x, y, 'ro')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Ejemplos basados en el libro de Python: Image processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
